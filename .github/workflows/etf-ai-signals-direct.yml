# ETF/Index/Commodity AI Signals (Direct )
# ========================================
# Processes ETFs, Indices, and Commodities using Gemini AI directly in GitHub Actions.
# Simpler than E2B version - runs sequentially but more reliable.
#
# TRIGGERS:
# - Manual dispatch only (removed auto-trigger to prevent accidental runs)

name: ETF/Index/Commodity AI Signals (Direct)

on:
  workflow_dispatch:
    inputs:
      target_date:
        description: 'Target date (YYYY-MM-DD). Leave empty for today.'
        required: false
        type: string
      batch_size:
        description: 'Number of assets per batch (default: 10)'
        required: false
        default: '10'
        type: string
      model:
        description: 'Gemini model to use'
        required: false
        default: 'gemini-3-flash-preview'
        type: string

env:
  PYTHON_VERSION: '3.11'

jobs:
  ai-analysis:
    name: ETF/Index/Commodity AI Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install psycopg2-binary google-genai
      
      - name: Determine target date
        id: date
        run: |
          if [ -n "${{ github.event.inputs.target_date }}" ]; then
            echo "date=${{ github.event.inputs.target_date }}" >> $GITHUB_OUTPUT
          else
            echo "date=$(date -u +%Y-%m-%d)" >> $GITHUB_OUTPUT
          fi
      
      - name: Get asset count
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python3 << 'EOF'
          import psycopg2
          import os
          
          db_url = os.environ['DATABASE_URL']
          conn = psycopg2.connect(db_url)
          cur = conn.cursor()
          cur.execute("SELECT COUNT(*) FROM assets WHERE asset_type IN ('etf', 'index', 'commodity') AND is_active = TRUE")
          count = cur.fetchone()[0]
          print(f'Total ETF/Index/Commodity assets to process: {count}')
          conn.close()
          EOF
      
      - name: Run AI analysis
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          echo "Starting ETF/Index/Commodity AI Analysis (Direct)"
          echo "Date: ${{ steps.date.outputs.date }}"
          echo "Batch Size: ${{ github.event.inputs.batch_size || '10' }}"
          echo "Model: ${{ github.event.inputs.model || 'gemini-3-flash-preview' }}"
          echo ""
          
          # Process in batches
          offset=0
          batch_size=${{ github.event.inputs.batch_size || '10' }}
          total_processed=0
          
          while true; do
            echo "Processing batch at offset $offset (batch size: $batch_size)..."
            
            python3 scripts/run_etf_ai_analysis_batch.py \
              --date ${{ steps.date.outputs.date }} \
              --model "${{ github.event.inputs.model || 'gemini-3-flash-preview' }}" \
              --offset $offset \
              --batch-size $batch_size || true
            
            total_processed=$((total_processed + batch_size))
            echo "Batch completed"
            
            offset=$((offset + batch_size))
            
            # Stop after processing 180 assets (safety limit for ETF+Index+Commodity)
            if [ $offset -ge 180 ]; then
              echo "Reached safety limit (180 assets)"
              break
            fi
            
            # Small delay between batches
            sleep 2
          done
          
          echo ""
          echo "ETF/Index/Commodity AI analysis completed"
          echo "Total assets attempted: $total_processed"
      
      - name: Report results
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          echo "ETF/Index/Commodity AI Analysis Summary"
          echo "=========================================="
          
          python3 << 'EOF'
          import psycopg2
          import os
          
          db_url = os.environ['DATABASE_URL']
          conn = psycopg2.connect(db_url)
          cur = conn.cursor()
          
          # Count reviews by asset type
          cur.execute("""
              SELECT a.asset_type, COUNT(*) FROM asset_ai_reviews aar
              JOIN assets a ON aar.asset_id::bigint = a.asset_id
              WHERE a.asset_type IN ('etf', 'index', 'commodity')
              GROUP BY a.asset_type
          """)
          
          print('AI reviews created by type:')
          for row in cur.fetchall():
              print(f'  {row[0]}: {row[1]}')
          
          # Show top by direction score
          cur.execute("""
              SELECT a.symbol, a.asset_type, aar.ai_attention_level, aar.ai_direction_score
              FROM asset_ai_reviews aar
              JOIN assets a ON aar.asset_id::bigint = a.asset_id
              WHERE a.asset_type IN ('etf', 'index', 'commodity')
              ORDER BY aar.ai_direction_score DESC NULLS LAST
              LIMIT 10
          """)
          
          rows = cur.fetchall()
          if rows:
              print('\nTop 10 by direction score:')
              for row in rows:
                  print(f'  {row[0]} ({row[1]}): {row[2]} (score: {row[3]})')
          
          conn.close()
          EOF
