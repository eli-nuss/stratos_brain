# Gemini API Research Notes for Company Chat Feature

## Source: https://ai.google.dev/gemini-api/docs/code-execution

### Code Execution Tool

The Gemini API provides a code execution tool that enables the model to generate and run Python code. The model can then learn iteratively from the code execution results until it arrives at a final output.

**Key Implementation Pattern:**

```python
from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="What is the sum of the first 50 prime numbers?",
    config=types.GenerateContentConfig(
        tools=[types.Tool(code_execution=types.ToolCodeExecution)]
    ),
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    if part.executable_code is not None:
        print(part.executable_code.code)
    if part.code_execution_result is not None:
        print(part.code_execution_result.output)
```

### Code Execution in Chat

You can use code execution as part of a chat session:

```python
from google import genai
from google.genai import types

client = genai.Client()

chat = client.chats.create(
    model="gemini-2.5-flash",
    config=types.GenerateContentConfig(
        tools=[types.Tool(code_execution=types.ToolCodeExecution)]
    ),
)

response = chat.send_message("I have a math question for you.")
print(response.text)

response = chat.send_message(
    "What is the sum of the first 50 prime numbers?"
)

for part in response.candidates[0].content.parts:
    if part.text is not None:
        print(part.text)
    if part.executable_code is not None:
        print(part.executable_code.code)
    if part.code_execution_result is not None:
        print(part.code_execution_result.output)
```

### Response Parts

The model returns several content parts when using code execution:
- `text`: Inline text generated by the model
- `executableCode`: Code generated by the model that is meant to be executed
- `codeExecutionResult`: Result of the executable code

### Visual Thinking (Gemini 3)

The Gemini 3 Flash model can write and execute Python code to actively manipulate and inspect images. This is called "Visual Thinking".

Use cases:
- Zoom and inspect: Model detects when details are too small and writes code to crop and re-examine
- Visual math: Multi-step calculations using code
- Image annotation: Annotate images to answer questions

### Input/Output (I/O)

Starting with Gemini 2.0 Flash, code execution supports:
- File input: Upload CSV and text files
- Graph output: Matplotlib graphs generated as part of the response
- Output files returned as inline images

---

## Dual-Tool Pattern (from user's pasted content)

For maximum agentic capability, enable both Google Search and Code Execution:

```python
from google import genai
from google.genai import types

client = genai.Client(api_key="YOUR_API_KEY")

# Define the Tool Configuration
# This enables BOTH Google Search (Grounding) and Code Execution
agent_tools = [
    types.Tool(
        google_search=types.GoogleSearch()  # Enable live web access
    ),
    types.Tool(
        code_execution=types.CodeExecution()  # Enable Python sandbox
    )
]

# Create the Chat Session
chat = client.chats.create(
    model="gemini-3.0-pro-preview",
    config=types.GenerateContentConfig(
        tools=agent_tools,
        temperature=0.4,  # Keep it lower for tool-use precision
    )
)

response = chat.send_message(
    "Find the last 5 closing prices of GOOGL stock and calculate the average."
)
print(response.text)
```

This allows the model to:
1. Fetch real-time data (Search)
2. Process/Analyze that data using Python (Code Execution)
3. Return a synthesized result

---

## Key Documentation Links to Review

1. Code Execution: https://ai.google.dev/gemini-api/docs/code-execution
2. Grounding (Search): https://ai.google.dev/gemini-api/docs/grounding
3. Function Calling: https://ai.google.dev/gemini-api/docs/function-calling
4. Computer Use: https://ai.google.dev/gemini-api/docs/computer-use
5. API Reference: https://ai.google.dev/api/python/google/genai


---

## Source: https://ai.google.dev/gemini-api/docs/google-search

### Grounding with Google Search

Grounding with Google Search connects the Gemini model to real-time web content. This allows Gemini to:
- Increase factual accuracy (reduce hallucinations)
- Access real-time information
- Provide citations with verifiable sources

**Implementation:**

```python
from google import genai
from google.genai import types

client = genai.Client()

grounding_tool = types.Tool(
    google_search=types.GoogleSearch()
)

config = types.GenerateContentConfig(
    tools=[grounding_tool]
)

response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="Who won the euro 2024?",
    config=config,
)

print(response.text)
```

### Grounding Response Metadata

When grounded, the response includes `groundingMetadata`:
- `webSearchQueries`: Array of search queries used
- `searchEntryPoint`: HTML/CSS for search widget
- `groundingChunks`: Array of web sources (uri and title)
- `groundingSupports`: Links text segments to sources for inline citations

---

## Source: https://ai.google.dev/gemini-api/docs/function-calling

### Function Calling

Function calling lets you connect models to external tools and APIs. The model determines when to call specific functions and provides the necessary parameters.

**Use Cases:**
1. Augment Knowledge: Access external sources like databases, APIs
2. Extend Capabilities: Use external tools for computations
3. Take Actions: Interact with external systems (scheduling, emails, etc.)

**Implementation Pattern:**

```python
from google import genai
from google.genai import types

# Define the function declaration
schedule_meeting_function = {
    "name": "schedule_meeting",
    "description": "Schedules a meeting with specified attendees at a given time and date.",
    "parameters": {
        "type": "object",
        "properties": {
            "attendees": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of people attending the meeting.",
            },
            "date": {
                "type": "string",
                "description": "Date of the meeting (e.g., '2024-07-29')",
            },
            "time": {
                "type": "string",
                "description": "Time of the meeting (e.g., '15:00')",
            },
            "topic": {
                "type": "string",
                "description": "The subject or topic of the meeting.",
            },
        },
        "required": ["attendees", "date", "time", "topic"],
    },
}

# Configure the client and tools
client = genai.Client()
tools = types.Tool(function_declarations=[schedule_meeting_function])
config = types.GenerateContentConfig(tools=[tools])

# Send request with function declarations
response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="Schedule a meeting with Bob and Alice for 03/14/2025 at 10:00 AM about the Q3 planning.",
    config=config,
)

# Check for a function call
if response.candidates[0].content.parts[0].function_call:
    function_call = response.candidates[0].content.parts[0].function_call
    print(f"Function to call: {function_call.name}")
    print(f"Arguments: {function_call.args}")
```

### Function Calling Flow

1. Define Function Declaration in application code
2. Call LLM with function declarations
3. Model determines if function call is helpful
4. Execute Function Code (your responsibility)
5. Send result back to model for user-friendly response

### Key Features

- **Parallel function calling**: Multiple functions in a single turn
- **Compositional function calling**: Functions in sequence
- **Automatic function calling** (Python only)
- **Multi-tool use**: Combine native tools with function calling

---

## Combining All Tools (Dual/Multi-Tool Pattern)

For maximum agentic capability, enable multiple tools together:

```python
from google import genai
from google.genai import types

client = genai.Client(api_key="YOUR_API_KEY")

# Define custom function declarations
get_stock_data_function = {
    "name": "get_stock_data",
    "description": "Retrieves stock data from the database",
    "parameters": {
        "type": "object",
        "properties": {
            "symbol": {"type": "string", "description": "Stock ticker symbol"},
            "date_range": {"type": "string", "description": "Date range for data"}
        },
        "required": ["symbol"]
    }
}

# Combine all tools
agent_tools = [
    types.Tool(google_search=types.GoogleSearch()),  # Web search
    types.Tool(code_execution=types.ToolCodeExecution),  # Python sandbox
    types.Tool(function_declarations=[get_stock_data_function])  # Custom functions
]

chat = client.chats.create(
    model="gemini-3.0-pro-preview",
    config=types.GenerateContentConfig(
        tools=agent_tools,
        temperature=0.4,
    )
)
```

This allows the model to:
1. Fetch real-time data via Google Search
2. Process/analyze data using Python code execution
3. Call custom functions to access your database or APIs
4. Return synthesized results
